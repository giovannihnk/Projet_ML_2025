import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

# TODO: Load data and splits if necessary


digits = load_digits()
x = digits.data
y = digits.target
x = x / 16.0
x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)


### TensorFlow is a powerful open-source deep learning framework developed by Google.
## It enables building and training neural networks efficiently,
##using optimized tensor computations.
## It supports CPU, GPU, and TPU acceleration, making it ideal for complex AI models.

#Keras is a high-level neural network API that runs on top of TensorFlow.
#It provides an easy-to-use interface for defining deep learning models without needing complex implementations.
#TensorFlow integrates Keras natively, making it ideal for rapid AI development.


# TODO: Create your first fully connected neural network with the following caracteristics:
# * 1 input layer
# * 1 hidden layer using 32 neurons
# * Input and hidden layers shall have relu activation functions
# * Output layer is activated with softmax
# * As input, we consider the pixels directly -- we'll look later into using engineered features

model = tf.keras.Sequential([
    tf.keras.Input(shape=(64,), name='input_image'),
    tf.keras.layers.Flatten(),                                   
    tf.keras.layers.Dense(32, activation='relu'),        # 32 neurones
    tf.keras.layers.Dense(10, activation='softmax')     
])

# TODO: Compile the model (setting parameters on how the model will learn from the data)
# Use adam optimizer, sparse categorical cross entropy as loss, and at least the accuracy as the metric
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# TODO: Train the model and store training and validation history
history = model.fit(x_train, y_train,
                    epochs=40,
                    batch_size=32,
                    validation_data=(x_test,y_test), 
                    verbose=1)

# Extract loss values
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot loss vs epochs
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss', marker='o')
plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss', marker='s')
plt.xlabel("Epochs")
plt.yscale("log")  # Apply log scale to the y-axis
plt.ylabel("Loss")
plt.title("Loss vs Epochs")
plt.legend()
plt.grid()
plt.show()

# Save the trained model
model.save("digit_classifier_model.keras")  # Sauvegarde au format Keras

# TODO:
# For the remaining time of the class, find a way to combine preprocessing + learning algorithm to achieve the best possible scores.
# Your final tuned model should be written in the test script provided for us to test during the oral exam.
#
# Enjoy, and good luck!
print("Modèle entraîné et sauvegardé.")
